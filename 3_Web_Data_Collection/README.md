# ğŸŒ Web Data Collection Project

## ğŸ“Œ Project Overview
This project demonstrates web scraping using Python to collect publicly available data from a website and store it into a CSV file.

The data was extracted from quotes.toscrape.com, a practice website designed for web scraping learning purposes.

This project is part of my Data Science Internship Portfolio.

---

## ğŸ¯ Objectives
- Send HTTP requests to a website
- Parse HTML content using BeautifulSoup
- Extract structured data (Quotes, Authors, Tags)
- Handle pagination (multiple pages)
- Store scraped data into CSV format

---

## ğŸ› ï¸ Technologies Used
- Python
- Requests
- BeautifulSoup
- Pandas

---

## ğŸ“‚ Files Included
- `web_scraping.py` â†’ Python script for scraping data
- `quotes.csv` â†’ Extracted dataset in CSV format
- `README.md` â†’ Project documentation

---

## ğŸ”„ Process Workflow
1. Send HTTP request to website
2. Parse HTML content
3. Extract required data fields
4. Store data into lists
5. Convert lists into Pandas DataFrame
6. Export data to CSV file

---

## ğŸ“Š Output
The script generates a CSV file containing:
- Quote Text
- Author Name
- Tags

---

## ğŸš€ How to Run the Project

1. Install required libraries:


2. Run the script:

